import OpenAI from 'openai';
import Replicate from 'replicate';

// Initialize AI services
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const replicate = new Replicate({
  auth: process.env.REPLICATE_API_TOKEN,
});

export interface ImageGenerationOptions {
  model?: 'dalle3' | 'stable-diffusion';
  size?: '1024x1024' | '1024x1792' | '1792x1024';
  quality?: 'standard' | 'hd';
  style?: 'vivid' | 'natural';
  n?: number;
}

export interface GeneratedImage {
  url: string;
  revised_prompt?: string;
  model: string;
  size: string;
  cost?: number;
}

/**
 * Generate an image using DALL-E 3
 */
export async function generateImageWithDALLE3(
  prompt: string,
  options: ImageGenerationOptions = {}
): Promise<GeneratedImage> {
  try {
    console.log('üé® Generating image with DALL-E 3:', prompt);
    
    const response = await openai.images.generate({
      model: 'dall-e-3',
      prompt,
      size: options.size || '1024x1024',
      quality: options.quality || 'standard',
      style: 'vivid', // Use 'vivid' for Disney-style vibrant colors
      n: 1,
    });

    if (!response.data || response.data.length === 0) {
      throw new Error('No image generated by DALL-E 3');
    }

    const image = response.data[0];
    
    return {
      url: image.url!,
      revised_prompt: image.revised_prompt,
      model: 'dall-e-3',
      size: options.size || '1024x1024',
      cost: 0.04, // DALL-E 3 cost per image
    };
  } catch (error) {
    console.error('‚ùå DALL-E 3 generation error:', error);
    throw new Error(`DALL-E 3 generation failed: ${error}`);
  }
}

/**
 * Generate an image using Stable Diffusion via Replicate
 */
export async function generateImageWithStableDiffusion(
  prompt: string,
  options: ImageGenerationOptions = {}
): Promise<GeneratedImage> {
  try {
    console.log('üé® Generating image with Stable Diffusion:', prompt);
    
    const output = await replicate.run(
      "stability-ai/stable-diffusion:27b93a2413e7f36cd83da926f3656280b2931564ff050bf9575f1fdf9bcd747e",
      {
        input: {
          prompt,
          width: 1024,
          height: 1024,
          num_outputs: 1,
          scheduler: "K_EULER",
          num_inference_steps: 50,
          guidance_scale: 7.5,
        }
      }
    );

    const imageUrl = Array.isArray(output) ? output[0] : output;
    
    return {
      url: imageUrl as string,
      model: 'stable-diffusion',
      size: '1024x1024',
      cost: 0.0023, // Replicate Stable Diffusion cost
    };
  } catch (error) {
    console.error('‚ùå Stable Diffusion generation error:', error);
    throw new Error(`Stable Diffusion generation failed: ${error}`);
  }
}

/**
 * Generate an image using the specified model
 */
export async function generateImage(
  prompt: string,
  options: ImageGenerationOptions = {}
): Promise<GeneratedImage> {
  const model = options.model || 'dalle3';
  
  switch (model) {
    case 'dalle3':
      return generateImageWithDALLE3(prompt, options);
    case 'stable-diffusion':
      return generateImageWithStableDiffusion(prompt, options);
    default:
      throw new Error(`Unsupported model: ${model}`);
  }
}

/**
 * Generate multiple images with the same prompt
 */
export async function generateMultipleImages(
  prompt: string,
  count: number,
  options: ImageGenerationOptions = {}
): Promise<GeneratedImage[]> {
  const promises = Array(count).fill(null).map(() => 
    generateImage(prompt, options)
  );
  
  return Promise.all(promises);
}

/**
 * Analyze an image using GPT-4 Vision to extract detailed style descriptors
 */
export async function analyzeImageStyle(imageUrl: string): Promise<string> {
  try {
    console.log('üîç Analyzing image style with GPT-4 Vision:', imageUrl);
    
    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [
        {
          role: 'system',
          content: `You are an expert art director and visual style analyst. Analyze the provided image and extract detailed style descriptors that can be used to recreate the same visual style in other images. Focus on:
- Artistic style (e.g., "Disney-style animation", "watercolor", "digital painting")
- Color palette and mood (warm/cool, vibrant/muted, bright/dark)
- Lighting characteristics (soft/harsh, warm/cool, direction)
- Character design approach (realistic/stylized, proportions, features)
- Overall mood and atmosphere (friendly/scary, whimsical/serious, magical/realistic)
- Composition style
- Texture and rendering quality

Return ONLY a detailed style description that can be used in image generation prompts. Be specific and detailed.`
        },
        {
          role: 'user',
          content: [
            {
              type: 'image_url',
              image_url: {
                url: imageUrl
              }
            },
            {
              type: 'text',
              text: 'Analyze this image and provide a detailed style description that can be used to match this exact visual style in other images.'
            }
          ] as any
        }
      ],
      max_tokens: 500,
    });

    const styleDescription = response.choices[0]?.message?.content || '';
    console.log('‚úÖ Extracted style description:', styleDescription);
    return styleDescription;
  } catch (error) {
    console.error('‚ùå Image style analysis error:', error);
    // Return empty string if analysis fails - we'll fall back to text-based matching
    return '';
  }
}

/**
 * Create a story-specific image prompt with character consistency
 */
export function createStoryImagePrompt(
  storyText: string,
  storyTitle: string,
  style: string = 'Disney-style animation, polished and professional, expressive characters, vibrant colors, soft rounded shapes, family-friendly aesthetic, cinematic quality',
  characters?: Array<{
    name: string;
    description?: string;
    appearancePrompt?: string;
    role?: string;
    emotion?: string;
    action?: string;
  }>,
  referenceImageUrl?: string,
  extractedStyleDescription?: string
): string {
  // Build character descriptions with better structure
  let characterSection = '';
  if (characters && characters.length > 0) {
    const characterParts = characters.map(char => {
      let desc = char.name;
      if (char.appearancePrompt) {
        desc += `, ${char.appearancePrompt}`;
      } else if (char.description) {
        desc += `, ${char.description}`;
      }
      if (char.emotion) {
        desc += `, showing ${char.emotion} expression`;
      }
      if (char.action) {
        desc += `, ${char.action}`;
      }
      return desc;
    });
    characterSection = ` Characters: ${characterParts.join('. ')}.`;
  }
  
  // Clean up the story text for better AI processing
  const cleanStoryText = storyText
    .replace(/\*\*/g, '') // Remove markdown bold
    .replace(/\*/g, '') // Remove markdown italic
    .replace(/#{1,6}\s/g, '') // Remove markdown headers
    .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1') // Convert markdown links to plain text
    .replace(/\n+/g, ' ') // Replace newlines with spaces
    .replace(/\s+/g, ' ') // Normalize whitespace
    .trim();
  
  // Use up to 600 characters of the story text for better context
  const sceneDescription = cleanStoryText.substring(0, 600).trim();
  
  // Add style reference instruction if we have a reference image or extracted style
  let styleReferenceSection = '';
  if (extractedStyleDescription) {
    // Use the AI-extracted style description for precise matching
    styleReferenceSection = ` CRITICAL STYLE MATCHING: ${extractedStyleDescription} You MUST match this exact style in every detail - same artistic approach, same color palette, same lighting, same character design style, same mood and atmosphere.`;
  } else if (referenceImageUrl) {
    // Fallback to text-based instructions if we don't have extracted style
    styleReferenceSection = ' CRITICAL: Match the exact same artistic style, color palette, lighting mood, character design approach, and visual aesthetic as the first scene image from this story. Use the same warm, inviting lighting (not dark or scary). Characters should have the same friendly, expressive design style (not menacing, scary, or horror-like). Maintain the same whimsical, storybook illustration quality with vibrant colors and soft, rounded shapes. Keep the same family-friendly, magical atmosphere throughout. Avoid dark, ominous, or scary elements. The visual style must be identical to the first image - same artistic approach, same mood, same character rendering style.';
  }
  
  // Build a well-structured prompt with clear sections
  // Structure: [Style] [Scene Description] [Characters] [Style Reference] [Quality Requirements]
  const prompt = `${style}. Scene: ${sceneDescription}${characterSection}${styleReferenceSection} High quality illustration, dynamic composition, expressive and appealing, warm inviting atmosphere, family-friendly, no text, no words, no writing, no letters, no dialogue boxes, no UI elements, no dark or scary elements`;
  
  return prompt;
}


/**
 * Generate a video using Replicate
 */
export async function generateVideoWithReplicate(
  prompt: string,
  imageUrl?: string
): Promise<{ url: string; cost: number }> {
  try {
    console.log('üé¨ Generating video with Replicate:', prompt);
    
    // Check if API token is set
    if (!process.env.REPLICATE_API_TOKEN) {
      throw new Error('REPLICATE_API_TOKEN environment variable is not set');
    }
    
    console.log('‚úÖ Replicate API token found');
    
    const Replicate = (await import('replicate')).default;
    const replicate = new Replicate({
      auth: process.env.REPLICATE_API_TOKEN,
    });

    // If we have an image, animate it. Otherwise skip for now.
    if (!imageUrl) {
      throw new Error('Video generation requires an existing image. Generate an image first, then convert it to video.');
    }

    // Use Kling v2.1 to animate an image
    console.log('üé¨ Calling Replicate API with Kling v2.1, image:', imageUrl);
    
    // Create and wait for the prediction
    const prediction = await replicate.predictions.create({
      model: "kwaivgi/kling-v2.1",
      input: {
        prompt: prompt.substring(0, 200), // Use story context for video animation
        start_image: imageUrl,
        aspect_ratio: "16:9",
        duration: 5, // 5 second video
        negative_prompt: "blurry, low quality, distorted"
      }
    });

    console.log('üîç Prediction created:', prediction.id, 'status:', prediction.status);

    // Wait for the prediction to complete
    let finalPrediction = prediction;
    while (finalPrediction.status !== 'succeeded' && finalPrediction.status !== 'failed' && finalPrediction.status !== 'canceled') {
      await new Promise(resolve => setTimeout(resolve, 2000)); // Poll every 2 seconds
      finalPrediction = await replicate.predictions.get(prediction.id);
      console.log('‚è≥ Prediction status:', finalPrediction.status);
    }

    if (finalPrediction.status === 'failed') {
      throw new Error(`Replicate prediction failed: ${finalPrediction.error}`);
    }

    if (finalPrediction.status === 'canceled') {
      throw new Error('Replicate prediction was canceled');
    }

    console.log('üîç Final prediction output type:', typeof finalPrediction.output);
    console.log('üîç Final prediction output:', JSON.stringify(finalPrediction.output, null, 2));

    // Extract video URL from the prediction output
    let videoUrl: string | null = null;
    const output = finalPrediction.output;
    
    if (typeof output === 'string') {
      videoUrl = output;
    } else if (Array.isArray(output) && output.length > 0) {
      videoUrl = output[0];
    } else if (output && typeof output === 'object') {
      videoUrl = (output as any).output || (output as any).url || (output as any)[0];
    }
    
    if (!videoUrl || typeof videoUrl !== 'string') {
      console.error('‚ùå Could not extract video URL from output:', output);
      throw new Error(`No video URL returned from Replicate. Output type: ${typeof output}, Output: ${JSON.stringify(output)}`);
    }

    console.log('‚úÖ Video generated:', videoUrl);

    return {
      url: videoUrl,
      cost: 0.10, // Approximate cost per video
    };
  } catch (error) {
    console.error('‚ùå Video generation error:', error);
    throw new Error(`Video generation failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
  }
}

// Legacy function name for compatibility
export const generateVideoWithRunway = generateVideoWithReplicate;
